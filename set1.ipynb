{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "\n",
    "# Importing the dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "dataset = pd.read_csv('/home/left/Downloads/spambase.data',header = None)\n",
    "# Changing pandas dataframe to numpy array\n",
    "X = dataset.iloc[:, 0:57].values # We have 58 columns\n",
    "y = dataset.iloc[:, 57].values # Set the output column\n",
    "\n",
    "# Normalizing the data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "Χ = sc.transform(X)\n",
    "\n",
    "input_train = []\n",
    "input_test = []\n",
    "output_train = []\n",
    "output_test = []\n",
    "\n",
    "# 10-fold cross-validation\n",
    "kf = KFold(n_splits = 10,shuffle = True)\n",
    "\n",
    "for train_index, test_index in kf.split(dataset):\n",
    "    \n",
    "    input_train.append(X[train_index])\n",
    "    input_test.append(X[test_index])\n",
    "    output_train.append(y[train_index])\n",
    "    output_test.append(y[test_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "\n",
    "# Importing the dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "dataset = pd.read_excel('/home/left/Downloads/default_of_credit_card_clients.xls',header = None)\n",
    "# Changing pandas dataframe to numpy array\n",
    "X = dataset.iloc[2:, 1:24].values\n",
    "y = dataset.iloc[2:, 24].values\n",
    "dataset = dataset.drop(columns=[0])\n",
    "dataset = dataset.drop([0, 1])\n",
    "\n",
    "# Normalizing the data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "Χ = sc.transform(X)\n",
    "\n",
    "input_train = []\n",
    "input_test = []\n",
    "output_train = []\n",
    "output_test = []\n",
    "\n",
    "# 10-fold cross-validation\n",
    "kf = KFold(n_splits = 10,shuffle = True)\n",
    "\n",
    "for train_index, test_index in kf.split(dataset):\n",
    "    \n",
    "    input_train.append(X[train_index])\n",
    "    input_test.append(X[test_index])\n",
    "    output_train.append(y[train_index].astype('int'))\n",
    "    output_test.append(y[test_index].astype('int'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.8989389795340943\n",
      "The F1 Score is 0.8644900912553191\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "\n",
    "average_acc = 0\n",
    "average_f1 = 0 \n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors = 25, p=2) #Euclidean distance\n",
    "    classifier = classifier.fit(input_train[i],output_train[i])\n",
    "    \n",
    "    y_pred = classifier.predict(input_test[i])\n",
    "    \n",
    "    average_acc += accuracy_score(output_test[i], y_pred)\n",
    "    average_f1 += f1_score(output_test[i],y_pred)\n",
    "\n",
    "print(\"The accuracy is\", average_acc/10)\n",
    "print(\"The F1 Score is\", average_f1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finished\n",
      "The accuracy is:  0.5868070357446007\n",
      "The F1 score is:  0.6568923535834693\n"
     ]
    }
   ],
   "source": [
    "#LVQ\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "# global variables\n",
    "alpha = 0.001\n",
    "acc = 0\n",
    "f1 = 0\n",
    "total_acc = []\n",
    "total_f1 = []\n",
    "first_class = []\n",
    "zero_class = []\n",
    "output_class = [] # y\n",
    "\n",
    "\n",
    "# separate all inputs base on their classes \n",
    "for i in range(10):\n",
    "    for j in range(len(output_train[i])):\n",
    "        if output_train[i][j] == 1:\n",
    "            first_class.append(input_train[i][j])\n",
    "            output_class.append(output_train[i][j])\n",
    "        elif output_train[i][j] == 0:\n",
    "            zero_class.append(input_train[i][j])\n",
    "            output_class.append(output_train[i][j])\n",
    "\n",
    "zero_class_mean = sum(zero_class) / len(zero_class) # init mean for first region (class 0)\n",
    "first_class_mean = sum(first_class) / len(first_class) # init mean for second region (class 1)\n",
    "\n",
    "first_std = np.std(first_class) # init std for first region\n",
    "zero_std = np.std(zero_class) # init std for second region\n",
    "\n",
    "centroids = {'mean':[zero_class_mean], 'std':[zero_std], 'Cj':[0]} # init first two centroids for each class\n",
    "centroids['mean'].append(first_class_mean) # init centroid for class 1\n",
    "centroids['std'].append(first_std)\n",
    "centroids['Cj'].append(1)\n",
    "\n",
    "input_x = first_class + zero_class # all input vectors\n",
    "\n",
    "def gaussian_similarity(input_x, max_similarity, pred):\n",
    "    \n",
    "    if pred==0:\n",
    "        for m in range(len(centroids['mean'])):\n",
    "            numerator = np.sum(np.power(input_x - centroids['mean'][m], 2))\n",
    "            temp = numerator/(2*(centroids['std'][m]**2))\n",
    "            gaussian = math.exp(-temp)\n",
    "\n",
    "            if (gaussian > max_similarity):\n",
    "                max_similarity = gaussian\n",
    "                winner_index = m\n",
    "        return winner_index\n",
    "\n",
    "    for m in range(len(centroids['mean'])):\n",
    "        numerator = np.sum(np.power(input_test[i][j] - centroids['mean'][m], 2))\n",
    "        temp = numerator/(2*(centroids['std'][m]**2))\n",
    "        gaussian = math.exp(-temp)\n",
    "        \n",
    "        if (gaussian > max_similarity):\n",
    "            max_similarity = gaussian\n",
    "            winner_index = m\n",
    "            y_pred = centroids['Cj'][winner_index]\n",
    "    return y_pred\n",
    "    \n",
    "# train the model \n",
    "for i in range(len(input_x)):\n",
    "\n",
    "    winner_index = gaussian_similarity(input_x[i], max_similarity = 0, pred = 0)\n",
    "\n",
    "    # success\n",
    "    if (output_class[i] == centroids['Cj'][winner_index]):\n",
    "        centroids['std'][winner_index] = centroids['std'][winner_index] + alpha*(distance.euclidean(input_x[i], centroids['mean'][winner_index]))\n",
    "        centroids['mean'][winner_index] = (1-alpha)*centroids['mean'][winner_index] + alpha*input_x[i]\n",
    "    # failure\n",
    "    else:\n",
    "        centroids['std'][winner_index] = centroids['std'][winner_index] - alpha*(distance.euclidean(input_x[i], centroids['mean'][winner_index]))\n",
    "        centroids['mean'][winner_index] = (1+alpha)*centroids['mean'][winner_index] - alpha*input_x[i]\n",
    "        # create new centroid\n",
    "        centroids['mean'].append(input_x[i])\n",
    "        centroids['std'].append(0.1*np.std(input_x))\n",
    "        centroids['Cj'].append(centroids['Cj'][winner_index])\n",
    "\n",
    "print('training finished')\n",
    "# make predictions and testing\n",
    "for i in range(10):\n",
    "    for j in range(len(output_test[i])):\n",
    "        y_pred = gaussian_similarity(input_test[i][j], max_similarity = 0, pred = 1)           \n",
    "        total_acc.append(y_pred)\n",
    "        total_f1.append(y_pred)\n",
    "\n",
    "    acc += accuracy_score(output_test[i], total_acc)\n",
    "    f1 += f1_score(output_test[i], total_acc)\n",
    "    total_f1.clear()\n",
    "    total_acc.clear()\n",
    "        \n",
    "print('The accuracy is: ', acc/10)\n",
    "print('The F1 score is: ', f1/10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4140 samples\n",
      "Epoch 1/20\n",
      "4140/4140 [==============================] - 1s 322us/sample - loss: 0.1957 - accuracy: 0.7070\n",
      "Epoch 2/20\n",
      "4140/4140 [==============================] - 1s 203us/sample - loss: 0.0888 - accuracy: 0.9012\n",
      "Epoch 3/20\n",
      "4140/4140 [==============================] - 1s 186us/sample - loss: 0.0692 - accuracy: 0.9186\n",
      "Epoch 4/20\n",
      "4140/4140 [==============================] - 1s 156us/sample - loss: 0.0623 - accuracy: 0.9244\n",
      "Epoch 5/20\n",
      "4140/4140 [==============================] - 1s 193us/sample - loss: 0.0583 - accuracy: 0.9314\n",
      "Epoch 6/20\n",
      "4140/4140 [==============================] - 1s 185us/sample - loss: 0.0558 - accuracy: 0.9355\n",
      "Epoch 7/20\n",
      "4140/4140 [==============================] - 1s 207us/sample - loss: 0.0544 - accuracy: 0.9350\n",
      "Epoch 8/20\n",
      "4140/4140 [==============================] - 1s 161us/sample - loss: 0.0531 - accuracy: 0.9379\n",
      "Epoch 9/20\n",
      "4140/4140 [==============================] - 1s 182us/sample - loss: 0.0524 - accuracy: 0.9379\n",
      "Epoch 10/20\n",
      "4140/4140 [==============================] - 1s 224us/sample - loss: 0.0513 - accuracy: 0.9389\n",
      "Epoch 11/20\n",
      "4140/4140 [==============================] - 1s 190us/sample - loss: 0.0507 - accuracy: 0.9370\n",
      "Epoch 12/20\n",
      "4140/4140 [==============================] - 1s 200us/sample - loss: 0.0499 - accuracy: 0.9401\n",
      "Epoch 13/20\n",
      "4140/4140 [==============================] - 1s 180us/sample - loss: 0.0497 - accuracy: 0.9384\n",
      "Epoch 14/20\n",
      "4140/4140 [==============================] - 1s 169us/sample - loss: 0.0494 - accuracy: 0.9396\n",
      "Epoch 15/20\n",
      "4140/4140 [==============================] - 1s 180us/sample - loss: 0.0484 - accuracy: 0.9401\n",
      "Epoch 16/20\n",
      "4140/4140 [==============================] - 1s 156us/sample - loss: 0.0484 - accuracy: 0.9420\n",
      "Epoch 17/20\n",
      "4140/4140 [==============================] - 1s 171us/sample - loss: 0.0478 - accuracy: 0.9428\n",
      "Epoch 18/20\n",
      "4140/4140 [==============================] - 1s 216us/sample - loss: 0.0471 - accuracy: 0.9435\n",
      "Epoch 19/20\n",
      "4140/4140 [==============================] - 1s 206us/sample - loss: 0.0468 - accuracy: 0.9413\n",
      "Epoch 20/20\n",
      "4140/4140 [==============================] - 1s 203us/sample - loss: 0.0462 - accuracy: 0.9437\n",
      "Train on 4141 samples\n",
      "Epoch 1/20\n",
      "4141/4141 [==============================] - 1s 316us/sample - loss: 0.1654 - accuracy: 0.7766\n",
      "Epoch 2/20\n",
      "4141/4141 [==============================] - 1s 165us/sample - loss: 0.0785 - accuracy: 0.9135\n",
      "Epoch 3/20\n",
      "4141/4141 [==============================] - 1s 233us/sample - loss: 0.0652 - accuracy: 0.9225\n",
      "Epoch 4/20\n",
      "4141/4141 [==============================] - 1s 143us/sample - loss: 0.0597 - accuracy: 0.9278\n",
      "Epoch 5/20\n",
      "4141/4141 [==============================] - 1s 194us/sample - loss: 0.0564 - accuracy: 0.9341\n",
      "Epoch 6/20\n",
      "4141/4141 [==============================] - 1s 205us/sample - loss: 0.0544 - accuracy: 0.9346\n",
      "Epoch 7/20\n",
      "4141/4141 [==============================] - 1s 180us/sample - loss: 0.0529 - accuracy: 0.9358\n",
      "Epoch 8/20\n",
      "4141/4141 [==============================] - 1s 239us/sample - loss: 0.0523 - accuracy: 0.9379\n",
      "Epoch 9/20\n",
      "4141/4141 [==============================] - 1s 244us/sample - loss: 0.0513 - accuracy: 0.9396\n",
      "Epoch 10/20\n",
      "4141/4141 [==============================] - 1s 206us/sample - loss: 0.0508 - accuracy: 0.9387\n",
      "Epoch 11/20\n",
      "4141/4141 [==============================] - 1s 237us/sample - loss: 0.0499 - accuracy: 0.9396\n",
      "Epoch 12/20\n",
      "4141/4141 [==============================] - 1s 152us/sample - loss: 0.0491 - accuracy: 0.9396\n",
      "Epoch 13/20\n",
      "4141/4141 [==============================] - 1s 201us/sample - loss: 0.0485 - accuracy: 0.9423\n",
      "Epoch 14/20\n",
      "4141/4141 [==============================] - 1s 208us/sample - loss: 0.0480 - accuracy: 0.9413\n",
      "Epoch 15/20\n",
      "4141/4141 [==============================] - 1s 195us/sample - loss: 0.0478 - accuracy: 0.9423\n",
      "Epoch 16/20\n",
      "4141/4141 [==============================] - 1s 238us/sample - loss: 0.0473 - accuracy: 0.9413\n",
      "Epoch 17/20\n",
      "4141/4141 [==============================] - 1s 232us/sample - loss: 0.0466 - accuracy: 0.9449\n",
      "Epoch 18/20\n",
      "4141/4141 [==============================] - 1s 216us/sample - loss: 0.0462 - accuracy: 0.9449\n",
      "Epoch 19/20\n",
      "4141/4141 [==============================] - 1s 215us/sample - loss: 0.0459 - accuracy: 0.9449\n",
      "Epoch 20/20\n",
      "4141/4141 [==============================] - 1s 215us/sample - loss: 0.0455 - accuracy: 0.9442\n",
      "Train on 4141 samples\n",
      "Epoch 1/20\n",
      "4141/4141 [==============================] - 1s 213us/sample - loss: 0.1638 - accuracy: 0.7645\n",
      "Epoch 2/20\n",
      "4141/4141 [==============================] - 1s 134us/sample - loss: 0.0779 - accuracy: 0.9109\n",
      "Epoch 3/20\n",
      "4141/4141 [==============================] - 1s 168us/sample - loss: 0.0643 - accuracy: 0.9225\n",
      "Epoch 4/20\n",
      "4141/4141 [==============================] - 1s 218us/sample - loss: 0.0586 - accuracy: 0.9280\n",
      "Epoch 5/20\n",
      "4141/4141 [==============================] - 1s 236us/sample - loss: 0.0554 - accuracy: 0.9329\n",
      "Epoch 6/20\n",
      "4141/4141 [==============================] - 1s 166us/sample - loss: 0.0534 - accuracy: 0.9358\n",
      "Epoch 7/20\n",
      "4141/4141 [==============================] - 1s 178us/sample - loss: 0.0529 - accuracy: 0.9346\n",
      "Epoch 8/20\n",
      "4141/4141 [==============================] - 1s 200us/sample - loss: 0.0516 - accuracy: 0.9353\n",
      "Epoch 9/20\n",
      "4141/4141 [==============================] - 1s 141us/sample - loss: 0.0504 - accuracy: 0.9372\n",
      "Epoch 10/20\n",
      "4141/4141 [==============================] - 1s 179us/sample - loss: 0.0503 - accuracy: 0.9367\n",
      "Epoch 11/20\n",
      "4141/4141 [==============================] - 1s 199us/sample - loss: 0.0492 - accuracy: 0.9391\n",
      "Epoch 12/20\n",
      "4141/4141 [==============================] - 1s 150us/sample - loss: 0.0486 - accuracy: 0.9411\n",
      "Epoch 13/20\n",
      "4141/4141 [==============================] - 1s 153us/sample - loss: 0.0480 - accuracy: 0.9411\n",
      "Epoch 14/20\n",
      "4141/4141 [==============================] - 1s 165us/sample - loss: 0.0478 - accuracy: 0.9404\n",
      "Epoch 15/20\n",
      "4141/4141 [==============================] - 1s 185us/sample - loss: 0.0473 - accuracy: 0.9416\n",
      "Epoch 16/20\n",
      "4141/4141 [==============================] - 1s 174us/sample - loss: 0.0467 - accuracy: 0.9437\n",
      "Epoch 17/20\n",
      "4141/4141 [==============================] - 1s 201us/sample - loss: 0.0462 - accuracy: 0.9445\n",
      "Epoch 18/20\n",
      "4141/4141 [==============================] - 1s 173us/sample - loss: 0.0458 - accuracy: 0.9445\n",
      "Epoch 19/20\n",
      "4141/4141 [==============================] - 1s 172us/sample - loss: 0.0455 - accuracy: 0.9440\n",
      "Epoch 20/20\n",
      "4141/4141 [==============================] - 1s 225us/sample - loss: 0.0452 - accuracy: 0.9445\n",
      "Train on 4141 samples\n",
      "Epoch 1/20\n",
      "4141/4141 [==============================] - 1s 286us/sample - loss: 0.1665 - accuracy: 0.7670\n",
      "Epoch 2/20\n",
      "4141/4141 [==============================] - 1s 211us/sample - loss: 0.0796 - accuracy: 0.9104\n",
      "Epoch 3/20\n",
      "4141/4141 [==============================] - 1s 188us/sample - loss: 0.0656 - accuracy: 0.9208\n",
      "Epoch 4/20\n",
      "4141/4141 [==============================] - 1s 171us/sample - loss: 0.0598 - accuracy: 0.9271\n",
      "Epoch 5/20\n",
      "4141/4141 [==============================] - 1s 187us/sample - loss: 0.0564 - accuracy: 0.9307\n",
      "Epoch 6/20\n",
      "4141/4141 [==============================] - 1s 170us/sample - loss: 0.0544 - accuracy: 0.9331\n",
      "Epoch 7/20\n",
      "4141/4141 [==============================] - 1s 179us/sample - loss: 0.0533 - accuracy: 0.9350\n",
      "Epoch 8/20\n",
      "4141/4141 [==============================] - 1s 167us/sample - loss: 0.0525 - accuracy: 0.9355\n",
      "Epoch 9/20\n",
      "4141/4141 [==============================] - 1s 144us/sample - loss: 0.0514 - accuracy: 0.9382\n",
      "Epoch 10/20\n",
      "4141/4141 [==============================] - 1s 199us/sample - loss: 0.0508 - accuracy: 0.9355\n",
      "Epoch 11/20\n",
      "4141/4141 [==============================] - 1s 205us/sample - loss: 0.0500 - accuracy: 0.9370\n",
      "Epoch 12/20\n",
      "4141/4141 [==============================] - 1s 194us/sample - loss: 0.0491 - accuracy: 0.9377\n",
      "Epoch 13/20\n",
      "4141/4141 [==============================] - 1s 183us/sample - loss: 0.0485 - accuracy: 0.9399\n",
      "Epoch 14/20\n",
      "4141/4141 [==============================] - 1s 167us/sample - loss: 0.0480 - accuracy: 0.9387\n",
      "Epoch 15/20\n",
      "4141/4141 [==============================] - 1s 194us/sample - loss: 0.0474 - accuracy: 0.9411\n",
      "Epoch 16/20\n",
      "4141/4141 [==============================] - 1s 209us/sample - loss: 0.0467 - accuracy: 0.9423\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4141/4141 [==============================] - 1s 167us/sample - loss: 0.0464 - accuracy: 0.9418\n",
      "Epoch 18/20\n",
      "4141/4141 [==============================] - 1s 153us/sample - loss: 0.0457 - accuracy: 0.9457\n",
      "Epoch 19/20\n",
      "4141/4141 [==============================] - 1s 157us/sample - loss: 0.0454 - accuracy: 0.9445\n",
      "Epoch 20/20\n",
      "4141/4141 [==============================] - 1s 194us/sample - loss: 0.0449 - accuracy: 0.9466\n",
      "Train on 4141 samples\n",
      "Epoch 1/20\n",
      "4141/4141 [==============================] - 1s 257us/sample - loss: 0.1674 - accuracy: 0.7588\n",
      "Epoch 2/20\n",
      "4141/4141 [==============================] - 1s 211us/sample - loss: 0.0796 - accuracy: 0.9123\n",
      "Epoch 3/20\n",
      "4141/4141 [==============================] - 1s 160us/sample - loss: 0.0663 - accuracy: 0.9222\n",
      "Epoch 4/20\n",
      "4141/4141 [==============================] - 1s 191us/sample - loss: 0.0606 - accuracy: 0.9268\n",
      "Epoch 5/20\n",
      "4141/4141 [==============================] - 1s 146us/sample - loss: 0.0577 - accuracy: 0.9326\n",
      "Epoch 6/20\n",
      "4141/4141 [==============================] - 1s 161us/sample - loss: 0.0555 - accuracy: 0.9338\n",
      "Epoch 7/20\n",
      "4141/4141 [==============================] - 1s 161us/sample - loss: 0.0540 - accuracy: 0.9346\n",
      "Epoch 8/20\n",
      "4141/4141 [==============================] - 1s 167us/sample - loss: 0.0531 - accuracy: 0.9355\n",
      "Epoch 9/20\n",
      "4141/4141 [==============================] - 1s 166us/sample - loss: 0.0521 - accuracy: 0.9360\n",
      "Epoch 10/20\n",
      "4141/4141 [==============================] - 1s 158us/sample - loss: 0.0515 - accuracy: 0.9387\n",
      "Epoch 11/20\n",
      "4141/4141 [==============================] - 1s 196us/sample - loss: 0.0508 - accuracy: 0.9377\n",
      "Epoch 12/20\n",
      "4141/4141 [==============================] - 1s 166us/sample - loss: 0.0506 - accuracy: 0.9389\n",
      "Epoch 13/20\n",
      "4141/4141 [==============================] - 1s 143us/sample - loss: 0.0498 - accuracy: 0.9396\n",
      "Epoch 14/20\n",
      "4141/4141 [==============================] - 1s 152us/sample - loss: 0.0493 - accuracy: 0.9401\n",
      "Epoch 15/20\n",
      "4141/4141 [==============================] - 1s 143us/sample - loss: 0.0490 - accuracy: 0.9423\n",
      "Epoch 16/20\n",
      "4141/4141 [==============================] - 1s 169us/sample - loss: 0.0484 - accuracy: 0.9406\n",
      "Epoch 17/20\n",
      "4141/4141 [==============================] - 1s 141us/sample - loss: 0.0480 - accuracy: 0.9428\n",
      "Epoch 18/20\n",
      "4141/4141 [==============================] - 1s 145us/sample - loss: 0.0475 - accuracy: 0.9435\n",
      "Epoch 19/20\n",
      "4141/4141 [==============================] - 1s 202us/sample - loss: 0.0471 - accuracy: 0.9423\n",
      "Epoch 20/20\n",
      "4141/4141 [==============================] - 1s 140us/sample - loss: 0.0465 - accuracy: 0.9433\n",
      "Train on 4141 samples\n",
      "Epoch 1/20\n",
      "4141/4141 [==============================] - 1s 248us/sample - loss: 0.1740 - accuracy: 0.7501\n",
      "Epoch 2/20\n",
      "4141/4141 [==============================] - 1s 137us/sample - loss: 0.0784 - accuracy: 0.9145\n",
      "Epoch 3/20\n",
      "4141/4141 [==============================] - 1s 148us/sample - loss: 0.0653 - accuracy: 0.9225\n",
      "Epoch 4/20\n",
      "4141/4141 [==============================] - 1s 149us/sample - loss: 0.0601 - accuracy: 0.9254\n",
      "Epoch 5/20\n",
      "4141/4141 [==============================] - 1s 165us/sample - loss: 0.0567 - accuracy: 0.9331\n",
      "Epoch 6/20\n",
      "4141/4141 [==============================] - 1s 145us/sample - loss: 0.0549 - accuracy: 0.9341\n",
      "Epoch 7/20\n",
      "4141/4141 [==============================] - 1s 167us/sample - loss: 0.0535 - accuracy: 0.9372\n",
      "Epoch 8/20\n",
      "4141/4141 [==============================] - 1s 145us/sample - loss: 0.0523 - accuracy: 0.9365\n",
      "Epoch 9/20\n",
      "4141/4141 [==============================] - 1s 183us/sample - loss: 0.0514 - accuracy: 0.9389\n",
      "Epoch 10/20\n",
      "4141/4141 [==============================] - 1s 180us/sample - loss: 0.0507 - accuracy: 0.9384\n",
      "Epoch 11/20\n",
      "4141/4141 [==============================] - 1s 150us/sample - loss: 0.0501 - accuracy: 0.9391\n",
      "Epoch 12/20\n",
      "4141/4141 [==============================] - 1s 150us/sample - loss: 0.0495 - accuracy: 0.9387\n",
      "Epoch 13/20\n",
      "4141/4141 [==============================] - 1s 164us/sample - loss: 0.0488 - accuracy: 0.9413\n",
      "Epoch 14/20\n",
      "4141/4141 [==============================] - 1s 156us/sample - loss: 0.0487 - accuracy: 0.9408\n",
      "Epoch 15/20\n",
      "4141/4141 [==============================] - 1s 158us/sample - loss: 0.0479 - accuracy: 0.9396\n",
      "Epoch 16/20\n",
      "4141/4141 [==============================] - 1s 136us/sample - loss: 0.0470 - accuracy: 0.9411\n",
      "Epoch 17/20\n",
      "4141/4141 [==============================] - 1s 154us/sample - loss: 0.0462 - accuracy: 0.9408\n",
      "Epoch 18/20\n",
      "4141/4141 [==============================] - 1s 141us/sample - loss: 0.0454 - accuracy: 0.9447\n",
      "Epoch 19/20\n",
      "4141/4141 [==============================] - 1s 145us/sample - loss: 0.0453 - accuracy: 0.9437\n",
      "Epoch 20/20\n",
      "4141/4141 [==============================] - 1s 150us/sample - loss: 0.0450 - accuracy: 0.9440\n",
      "Train on 4141 samples\n",
      "Epoch 1/20\n",
      "4141/4141 [==============================] - 1s 234us/sample - loss: 0.1760 - accuracy: 0.7445\n",
      "Epoch 2/20\n",
      "4141/4141 [==============================] - 1s 172us/sample - loss: 0.0825 - accuracy: 0.9106\n",
      "Epoch 3/20\n",
      "4141/4141 [==============================] - 1s 172us/sample - loss: 0.0669 - accuracy: 0.9227\n",
      "Epoch 4/20\n",
      "4141/4141 [==============================] - 1s 169us/sample - loss: 0.0604 - accuracy: 0.9276\n",
      "Epoch 5/20\n",
      "4141/4141 [==============================] - 1s 182us/sample - loss: 0.0571 - accuracy: 0.9324\n",
      "Epoch 6/20\n",
      "4141/4141 [==============================] - 1s 155us/sample - loss: 0.0547 - accuracy: 0.9358\n",
      "Epoch 7/20\n",
      "4141/4141 [==============================] - 1s 177us/sample - loss: 0.0529 - accuracy: 0.9375\n",
      "Epoch 8/20\n",
      "4141/4141 [==============================] - 1s 165us/sample - loss: 0.0520 - accuracy: 0.9375\n",
      "Epoch 9/20\n",
      "4141/4141 [==============================] - 1s 163us/sample - loss: 0.0512 - accuracy: 0.9399\n",
      "Epoch 10/20\n",
      "4141/4141 [==============================] - 1s 175us/sample - loss: 0.0504 - accuracy: 0.9394\n",
      "Epoch 11/20\n",
      "4141/4141 [==============================] - 1s 169us/sample - loss: 0.0498 - accuracy: 0.9379\n",
      "Epoch 12/20\n",
      "4141/4141 [==============================] - 1s 173us/sample - loss: 0.0492 - accuracy: 0.9394\n",
      "Epoch 13/20\n",
      "4141/4141 [==============================] - 1s 147us/sample - loss: 0.0485 - accuracy: 0.9418\n",
      "Epoch 14/20\n",
      "4141/4141 [==============================] - 1s 180us/sample - loss: 0.0480 - accuracy: 0.9418\n",
      "Epoch 15/20\n",
      "4141/4141 [==============================] - 1s 188us/sample - loss: 0.0474 - accuracy: 0.9442\n",
      "Epoch 16/20\n",
      "4141/4141 [==============================] - 1s 154us/sample - loss: 0.0472 - accuracy: 0.9428\n",
      "Epoch 17/20\n",
      "4141/4141 [==============================] - 1s 194us/sample - loss: 0.0468 - accuracy: 0.9445\n",
      "Epoch 18/20\n",
      "4141/4141 [==============================] - 1s 189us/sample - loss: 0.0461 - accuracy: 0.9459\n",
      "Epoch 19/20\n",
      "4141/4141 [==============================] - 1s 193us/sample - loss: 0.0463 - accuracy: 0.9430\n",
      "Epoch 20/20\n",
      "4141/4141 [==============================] - 1s 192us/sample - loss: 0.0456 - accuracy: 0.9457\n",
      "Train on 4141 samples\n",
      "Epoch 1/20\n",
      "4141/4141 [==============================] - 1s 308us/sample - loss: 0.1691 - accuracy: 0.7696\n",
      "Epoch 2/20\n",
      "4141/4141 [==============================] - 1s 155us/sample - loss: 0.0792 - accuracy: 0.9150\n",
      "Epoch 3/20\n",
      "4141/4141 [==============================] - 1s 161us/sample - loss: 0.0672 - accuracy: 0.9186\n",
      "Epoch 4/20\n",
      "4141/4141 [==============================] - 1s 189us/sample - loss: 0.0613 - accuracy: 0.9247\n",
      "Epoch 5/20\n",
      "4141/4141 [==============================] - 1s 163us/sample - loss: 0.0580 - accuracy: 0.9326\n",
      "Epoch 6/20\n",
      "4141/4141 [==============================] - 1s 174us/sample - loss: 0.0559 - accuracy: 0.9333\n",
      "Epoch 7/20\n",
      "4141/4141 [==============================] - 1s 177us/sample - loss: 0.0549 - accuracy: 0.9329\n",
      "Epoch 8/20\n",
      "4141/4141 [==============================] - 1s 163us/sample - loss: 0.0536 - accuracy: 0.9333\n",
      "Epoch 9/20\n",
      "4141/4141 [==============================] - 1s 177us/sample - loss: 0.0526 - accuracy: 0.9348\n",
      "Epoch 10/20\n",
      "4141/4141 [==============================] - 1s 160us/sample - loss: 0.0522 - accuracy: 0.9370\n",
      "Epoch 11/20\n",
      "4141/4141 [==============================] - 1s 167us/sample - loss: 0.0512 - accuracy: 0.9387\n",
      "Epoch 12/20\n",
      "4141/4141 [==============================] - 1s 191us/sample - loss: 0.0506 - accuracy: 0.9391\n",
      "Epoch 13/20\n",
      "4141/4141 [==============================] - 1s 177us/sample - loss: 0.0498 - accuracy: 0.9408\n",
      "Epoch 14/20\n",
      "4141/4141 [==============================] - 1s 164us/sample - loss: 0.0494 - accuracy: 0.9379\n",
      "Epoch 15/20\n",
      "4141/4141 [==============================] - 1s 186us/sample - loss: 0.0486 - accuracy: 0.9425\n",
      "Epoch 16/20\n",
      "4141/4141 [==============================] - 1s 172us/sample - loss: 0.0486 - accuracy: 0.9411\n",
      "Epoch 17/20\n",
      "4141/4141 [==============================] - 1s 172us/sample - loss: 0.0479 - accuracy: 0.9430\n",
      "Epoch 18/20\n",
      "4141/4141 [==============================] - 1s 201us/sample - loss: 0.0469 - accuracy: 0.9447\n",
      "Epoch 19/20\n",
      "4141/4141 [==============================] - 1s 172us/sample - loss: 0.0467 - accuracy: 0.9452\n",
      "Epoch 20/20\n",
      "4141/4141 [==============================] - 1s 126us/sample - loss: 0.0465 - accuracy: 0.9449\n",
      "Train on 4141 samples\n",
      "Epoch 1/20\n",
      "4141/4141 [==============================] - 1s 279us/sample - loss: 0.1740 - accuracy: 0.7588\n",
      "Epoch 2/20\n",
      "4141/4141 [==============================] - 1s 133us/sample - loss: 0.0801 - accuracy: 0.9121\n",
      "Epoch 3/20\n",
      "4141/4141 [==============================] - 1s 171us/sample - loss: 0.0663 - accuracy: 0.9208\n",
      "Epoch 4/20\n",
      "4141/4141 [==============================] - 1s 188us/sample - loss: 0.0606 - accuracy: 0.9268\n",
      "Epoch 5/20\n",
      "4141/4141 [==============================] - 1s 158us/sample - loss: 0.0576 - accuracy: 0.9312\n",
      "Epoch 6/20\n",
      "4141/4141 [==============================] - 1s 208us/sample - loss: 0.0554 - accuracy: 0.9341\n",
      "Epoch 7/20\n",
      "4141/4141 [==============================] - 1s 177us/sample - loss: 0.0541 - accuracy: 0.9355\n",
      "Epoch 8/20\n",
      "4141/4141 [==============================] - 1s 181us/sample - loss: 0.0530 - accuracy: 0.9370\n",
      "Epoch 9/20\n",
      "4141/4141 [==============================] - 1s 214us/sample - loss: 0.0526 - accuracy: 0.9382\n",
      "Epoch 10/20\n",
      "4141/4141 [==============================] - 1s 164us/sample - loss: 0.0519 - accuracy: 0.9387\n",
      "Epoch 11/20\n",
      "4141/4141 [==============================] - 1s 188us/sample - loss: 0.0508 - accuracy: 0.9389\n",
      "Epoch 12/20\n",
      "4141/4141 [==============================] - 1s 203us/sample - loss: 0.0502 - accuracy: 0.9406\n",
      "Epoch 13/20\n",
      "4141/4141 [==============================] - 1s 165us/sample - loss: 0.0498 - accuracy: 0.9384\n",
      "Epoch 14/20\n",
      "4141/4141 [==============================] - 1s 153us/sample - loss: 0.0488 - accuracy: 0.9411\n",
      "Epoch 15/20\n",
      "4141/4141 [==============================] - 1s 184us/sample - loss: 0.0484 - accuracy: 0.9430\n",
      "Epoch 16/20\n",
      "4141/4141 [==============================] - 1s 177us/sample - loss: 0.0481 - accuracy: 0.9435\n",
      "Epoch 17/20\n",
      "4141/4141 [==============================] - 1s 168us/sample - loss: 0.0479 - accuracy: 0.9428\n",
      "Epoch 18/20\n",
      "4141/4141 [==============================] - 1s 201us/sample - loss: 0.0471 - accuracy: 0.9449\n",
      "Epoch 19/20\n",
      "4141/4141 [==============================] - 1s 166us/sample - loss: 0.0469 - accuracy: 0.9454\n",
      "Epoch 20/20\n",
      "4141/4141 [==============================] - 1s 179us/sample - loss: 0.0462 - accuracy: 0.9449\n",
      "Train on 4141 samples\n",
      "Epoch 1/20\n",
      "4141/4141 [==============================] - 2s 392us/sample - loss: 0.1539 - accuracy: 0.7950\n",
      "Epoch 2/20\n",
      "4141/4141 [==============================] - 1s 199us/sample - loss: 0.0764 - accuracy: 0.9160\n",
      "Epoch 3/20\n",
      "4141/4141 [==============================] - 1s 241us/sample - loss: 0.0642 - accuracy: 0.9244\n",
      "Epoch 4/20\n",
      "4141/4141 [==============================] - 1s 219us/sample - loss: 0.0589 - accuracy: 0.9302\n",
      "Epoch 5/20\n",
      "4141/4141 [==============================] - 1s 203us/sample - loss: 0.0561 - accuracy: 0.9317\n",
      "Epoch 6/20\n",
      "4141/4141 [==============================] - 1s 183us/sample - loss: 0.0542 - accuracy: 0.9329\n",
      "Epoch 7/20\n",
      "4141/4141 [==============================] - 1s 190us/sample - loss: 0.0528 - accuracy: 0.9355\n",
      "Epoch 8/20\n",
      "4141/4141 [==============================] - 1s 182us/sample - loss: 0.0519 - accuracy: 0.9377\n",
      "Epoch 9/20\n",
      "4141/4141 [==============================] - 1s 206us/sample - loss: 0.0511 - accuracy: 0.9372\n",
      "Epoch 10/20\n",
      "4141/4141 [==============================] - 1s 219us/sample - loss: 0.0502 - accuracy: 0.9358\n",
      "Epoch 11/20\n",
      "4141/4141 [==============================] - 1s 193us/sample - loss: 0.0488 - accuracy: 0.9391\n",
      "Epoch 12/20\n",
      "4141/4141 [==============================] - 1s 187us/sample - loss: 0.0480 - accuracy: 0.9404\n",
      "Epoch 13/20\n",
      "4141/4141 [==============================] - 1s 193us/sample - loss: 0.0478 - accuracy: 0.9413\n",
      "Epoch 14/20\n",
      "4141/4141 [==============================] - 1s 227us/sample - loss: 0.0469 - accuracy: 0.9423\n",
      "Epoch 15/20\n",
      "4141/4141 [==============================] - 1s 239us/sample - loss: 0.0463 - accuracy: 0.9442\n",
      "Epoch 16/20\n",
      "4141/4141 [==============================] - 1s 220us/sample - loss: 0.0460 - accuracy: 0.9435\n",
      "Epoch 17/20\n",
      "4141/4141 [==============================] - 1s 181us/sample - loss: 0.0453 - accuracy: 0.9442\n",
      "Epoch 18/20\n",
      "4141/4141 [==============================] - 1s 222us/sample - loss: 0.0450 - accuracy: 0.9449\n",
      "Epoch 19/20\n",
      "4141/4141 [==============================] - 1s 300us/sample - loss: 0.0446 - accuracy: 0.9476\n",
      "Epoch 20/20\n",
      "4141/4141 [==============================] - 1s 268us/sample - loss: 0.0445 - accuracy: 0.9469\n",
      "The accuracy is 0.9350146185041968\n",
      "The F1 Score is 0.9165276730289257\n"
     ]
    }
   ],
   "source": [
    "#MLP\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "#https://www.programcreek.com/python/example/89667/keras.layers.Dense\n",
    "#https://keras.io/models/model/\n",
    "#https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
    "#importing the libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "average_acc = 0\n",
    "average_f1 = 0\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    nn = tf.keras.Sequential()\n",
    "\n",
    "    nn.add(layers.Dense(50, input_dim = 57, activation = 'sigmoid')) #densely-connected 1st layer and 1st hidden layer\n",
    "\n",
    "    nn.add(layers.Dense(70, activation = 'sigmoid')) #second hidden layer with 15 units\n",
    "\n",
    "    nn.add(layers.Dense(1, activation = 'sigmoid')) #output layer\n",
    "    \n",
    "    nn.compile(optimizer='adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "    \n",
    "    nn.fit(input_train[i], output_train[i], epochs=20, batch_size=32)\n",
    "    \n",
    "    # Performance on test data\n",
    "    # If the prediction is greater than 0.5 then the output is 1 else the output is 0\n",
    "    y_pred = nn.predict(input_test[i])\n",
    "    y_pred = (y_pred > 0.5)\n",
    "            \n",
    "    average_acc += accuracy_score(output_test[i], y_pred)\n",
    "    average_f1 += f1_score(output_test[i], y_pred)\n",
    "\n",
    "print(\"The accuracy is\", average_acc/10)\n",
    "print(\"The F1 Score is\", average_f1/10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is\n",
      "0.9284914646798075\n",
      "The F1 Score is\n",
      "0.9075703410081364\n"
     ]
    }
   ],
   "source": [
    "#SVM_linear\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "average_acc = 0\n",
    "average_f1 = 0\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    svm = SVC(kernel='linear', gamma='auto') # Linear Kernel\n",
    "    svm = svm.fit(input_train[i],output_train[i])\n",
    "    \n",
    "    y_pred = svm.predict(input_test[i])\n",
    "    \n",
    "    average_acc += accuracy_score(output_test[i], y_pred)\n",
    "    average_f1 += f1_score(output_test[i],y_pred)\n",
    "\n",
    "print(\"The accuracy is\")\n",
    "print(average_acc/10)\n",
    "\n",
    "print(\"The F1 Score is\")\n",
    "print(average_f1/10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is\n",
      "0.9334891068565501\n",
      "The F1 Score is\n",
      "0.9136590583366064\n"
     ]
    }
   ],
   "source": [
    "#SVM_gaussian\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "average_acc = 0\n",
    "average_f1 = 0\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    svm = SVC(kernel='rbf', gamma='auto') # Gaussian Kernel\n",
    "    svm = svm.fit(input_train[i],output_train[i])\n",
    "    \n",
    "    y_pred = svm.predict(input_test[i])\n",
    "    average_acc += accuracy_score(output_test[i], y_pred)\n",
    "    average_f1 += f1_score(output_test[i],y_pred)\n",
    "\n",
    "print(\"The accuracy is\")\n",
    "print(average_acc/10)\n",
    "\n",
    "print(\"The F1 Score is\")\n",
    "print(average_f1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.8183061397717626\n",
      "The F1 Score is 0.8050742389388716\n"
     ]
    }
   ],
   "source": [
    "#NaiveBayes\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    " \n",
    "average_acc = 0\n",
    "average_f1 = 0\n",
    "    \n",
    "for i in range(10):\n",
    "    \n",
    "    nb = GaussianNB()\n",
    "    nb = nb.fit(input_train[i],output_train[i])\n",
    "    \n",
    "    y_pred = nb.predict(input_test[i])\n",
    "    \n",
    "    average_acc += accuracy_score(output_test[i], y_pred)\n",
    "    average_f1 += f1_score(output_test[i],y_pred)\n",
    "\n",
    "print(\"The accuracy is\", average_acc/10)\n",
    "print(\"The F1 Score is\", average_f1/10)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
